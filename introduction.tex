\chapter{Introduction}

\section{Background}

\begin{itemize}
    \item ML is cool
    \item TDA is cool
    \item Decision boundaries are cool
    \item Why the intersection of these three may be cool
\end{itemize}

% \subsection{Decision boundaries in machine learning}

% A classifier $f: \mathcal{R} \to \{1, \ldots, N\}$ partitions the input space $\mathcal{R}$ into $N$ regions
% corresponding to different class predictions.
% The decision boundary is the union of the boundaries of the regions, i.e., the
% set of points where the classifier changes its decision.

% The geometry and topology of decision boundaries are closely related to the classifier's behavior.
% Complex decision boundaries may indicate overfitting, while oversimplified boundaries
% may suggest underfitting. However, quantifying this complexity remains challenging,
% particularly in high-dimensional spaces.

% \subsection{Topological Data Analysis}

% Topological Data Analysis (TDA) provides tools for studying the shape and structure
% of data through the lens of topology. Unlike geometric approaches that rely on
% distances and angles, topological methods focus on qualitative features such as
% connected components and holes that persist across different scales.

% A key insight of TDA is that topological features can be meaningfully computed
% from discrete samples of continuous objects. This is particularly relevant
% for analyzing decision boundaries, which are typically only accessible through
% point samples.
% \todo{Maybe this goes into introduction}

\section{Objectives}

Yoink from the proposal.

\begin{itemize}
    \item Explore homological changes in decision boundaries during model training.
    \item Investigate connections between topological features and overfitting/underfitting.
    \item Extend the Labeled Vietoris-Rips complex to multiclass classification.
\end{itemize}
